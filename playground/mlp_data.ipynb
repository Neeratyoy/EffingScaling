{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from itertools import product\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scaling.utils import (\n",
    "    get_pareto_frontier, \n",
    "    get_final_points_from_curve_set, \n",
    "    fit_linear_model,\n",
    "    functional_form_chin3,\n",
    "    fit_parametric_form,\n",
    "    fit_parametric_form_stable,\n",
    "    functional_form_chin3_stable,\n",
    ")\n",
    "from scaling.visualize import visualize_train_curves, plot_line_fit, plot_isoflops"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_col_list = [\"base_N\", \"target_N\", \"tkpm\", \"shrink\"]\n",
    "\n",
    "def preprocess_warmstarting(df, y_col_to_smooth=None, smoothing_window=100):\n",
    "    __df = pd.DataFrame()\n",
    "    for i, x in enumerate(df.groupby(unique_col_list)):\n",
    "        _df = x[1].sort_values(by=\"flops\")\n",
    "        # smooth it\n",
    "        if y_col_to_smooth is not None:\n",
    "            # +\"_smoothed\"\n",
    "            _df[y_col_to_smooth] = _df[y_col_to_smooth].rolling(smoothing_window, win_type='gaussian', min_periods=1).mean(std=smoothing_window / 10)\n",
    "        \n",
    "        # scaling tokens and flops to the max\n",
    "        max_intended_tokens = (_df.iloc[-1][\"target_N\"] * _df.iloc[-1][\"tkpm\"])\n",
    "        if abs((max_intended_tokens -  _df[\"tokens\"].max()) / _df[\"tokens\"].max()) > 0.01:\n",
    "            print(\"Wrong tkpm: \", x[0])\n",
    "            continue\n",
    "        _df[\"tokens\"] = np.round(max_intended_tokens / _df[\"tokens\"].max() * _df[\"tokens\"])\n",
    "        \n",
    "        max_intended_flops = 6. * max_intended_tokens * _df[\"target_N\"]\n",
    "        _df[\"flops\"] = np.round(max_intended_flops / _df[\"flops\"].max() * _df[\"flops\"])\n",
    "        \n",
    "        __df = pd.concat([__df, _df])\n",
    "    return __df"
   ],
   "id": "bd4f50bea554bb47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlp_df = pd.read_parquet(\n",
    "    \"../data/mlp_results.parquet\",\n",
    ")\n",
    "# warmstarting_df = preprocess_warmstarting(warmstarting_df)\n",
    "display(mlp_df)"
   ],
   "id": "c4eda9dc7d708f54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_loss_at_flops(df: pd.DataFrame, flop_intervals: list[float], y_col: str, unique_col_list = list[str], add_base_compute=False) -> pd.Series:\n",
    "    \"\"\"Get the loss at a specific flop value by interpolation.\"\"\"\n",
    "    x_col = \"flops\"\n",
    "    best_learning_curve = None\n",
    "    best_final_loss = float('inf')\n",
    "\n",
    "    for i, x in enumerate(df.groupby(unique_col_list)):\n",
    "        _df = x[1].dropna(subset=[y_col]).sort_values(by=x_col)\n",
    "        if add_base_compute:\n",
    "            base_flops = 6. * 20. * _df.iloc[0]['base_N']**2\n",
    "            _df[x_col] += base_flops\n",
    "        final_loss = _df.iloc[-1][y_col]\n",
    "        if final_loss < best_final_loss:\n",
    "            best_final_loss = final_loss\n",
    "            best_learning_curve = pd.Series(\n",
    "                data=_df[y_col].values,\n",
    "                index=_df[x_col].values\n",
    "            )\n",
    "    \n",
    "    # add the flops into the Series if not present\n",
    "    for flop in flop_intervals:\n",
    "        if flop not in best_learning_curve.index:\n",
    "            best_learning_curve.loc[flop] = np.nan\n",
    "    best_learning_curve = best_learning_curve.sort_index()\n",
    "    # interpolate nans\n",
    "    best_learning_curve = best_learning_curve.interpolate(method='linear')\n",
    "    return best_learning_curve.loc[flop_intervals]"
   ],
   "id": "46657a439a993ea2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SHRINK = 0.4\n",
    "ADD_BASE_COMPUTE = False\n",
    "TKPM = 20.\n",
    "MIN_FLOPS_SCALE_FACTOR = 10\n",
    "\n",
    "warmstarting_tkpms_df = warmstarting_df[warmstarting_df['tkpm']==TKPM]\n",
    "\n",
    "target_models = sorted(warmstarting_tkpms_df['target_N'].unique())\n",
    "target_models = target_models[1:-1]  # skip the smallest model\n",
    "fig, axes = plt.subplots(1, len(target_models), figsize=(5 * len(target_models), 5), layout='constrained');\n",
    "for i, target_model in enumerate(target_models):\n",
    "    target_model_df = warmstarting_tkpms_df[warmstarting_tkpms_df['target_N']==target_model]\n",
    "    no_growth_df = target_model_df[target_model_df['method']=='mup']\n",
    "    \n",
    "    # calculate flop intervals\n",
    "    max_flops = no_growth_df['flops'].max()\n",
    "    min_flops = max_flops / MIN_FLOPS_SCALE_FACTOR\n",
    "    flop_intervals = np.linspace(min_flops, max_flops, 7)\n",
    "    flops_df = pd.DataFrame()\n",
    "    \n",
    "    # add growth factor == 1\n",
    "    no_growth_df = no_growth_df[no_growth_df[\"base_N\"]==no_growth_df[\"base_N\"].max()]\n",
    "    flops_df[1.] = get_loss_at_flops(no_growth_df, flop_intervals, y_col, unique_col_list)\n",
    "    \n",
    "    # add growth factor > 1\n",
    "    shrink_target_model_df = target_model_df[target_model_df['shrink'] == SHRINK]\n",
    "    shrink_target_model_df = target_model_df[target_model_df['method'] == 'warmstart']\n",
    "    # check if it is in a shrink list\n",
    "    \n",
    "    base_models = sorted(shrink_target_model_df['base_N'].unique(), reverse=True)\n",
    "    for base_model in base_models:\n",
    "        base_model_df = shrink_target_model_df[shrink_target_model_df['base_N']==base_model]\n",
    "        \n",
    "        growth_factor = target_model / base_model\n",
    "        growth_df = base_model_df[base_model_df['target_N']==target_model]\n",
    "        flops_df[growth_factor] = get_loss_at_flops(growth_df, flop_intervals, y_col, unique_col_list, add_base_compute=ADD_BASE_COMPUTE)\n",
    "        # select only the shrink factor we want\n",
    "    axes[i].set_title(f\"Target N: {(target_model/1_000_000):3.1f}M\")\n",
    "    plot_isoflops(\n",
    "        axes[i],\n",
    "        flops_df,\n",
    "        disable_y_label=(i == len(target_models) - 1),\n",
    "    )\n",
    "    \n",
    "# add figure wide xlabel\n",
    "fig.supxlabel(\"Growth Factor\", fontsize=15)\n",
    "fig.supylabel(y_col, fontsize=15)"
   ],
   "id": "f78935a966db129a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
